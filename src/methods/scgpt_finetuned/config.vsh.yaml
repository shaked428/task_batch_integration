__merge__: ../../api/base_method.yaml

name: scgpt_finetuned
label: scGPT (fine-tuned)
summary: "A foundation model for single-cell biology (fine-tuned)"
description: |
  scGPT is a foundation model for single-cell biology based on a generative
  pre-trained transformer and trained on a repository of over 33 million cells.

  Here, we fine-tune the pre-trained model for the batch integration task.
references:
  doi:
    - 10.1038/s41592-024-02201-0
links:
  documentation: https://scgpt.readthedocs.io/en/latest/
  repository: https://github.com/bowang-lab/scGPT

info:
  method_types: [embedding]
  preferred_normalization: counts
  variants:
    scgpt_finetuned_default:

arguments:
  - name: --model_name
    type: string
    description: String giving the name of the scGPT model to use
    choices: ["scGPT_human", "scGPT_CP"]
    default: "scGPT_human"
  - name: --model
    type: file
    description: |
      Path to the directory containing the scGPT model specified by model_name
      or a .zip/.tar.gz archive to extract. If not given the model will be
      downloaded.
    required: false
  - name: --n_hvg
    type: integer
    default: 3000
    description: Number of highly variable genes to use.

resources:
  - type: python_script
    path: script.py
  - path: /src/utils/read_anndata_partial.py
  - path: scgpt_functions.py

engines:
  - type: docker
    image: openproblems/base_pytorch_nvidia:1.0.0
    # TODO: Try to find working installation of flash attention (flash-attn<1.0.5)
    setup:
      - type: python
        pypi:
          - gdown
          - scgpt # Install from PyPI to get dependencies
      - type: docker
        # Force re-installing from GitHub to get bug fixes
        run: pip install --upgrade --no-deps --force-reinstall git+https://github.com/bowang-lab/scGPT.git

runners:
  - type: executable
  - type: nextflow
    directives:
      label: [hightime, midmem, midcpu, biggpu]
